{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a692517",
   "metadata": {},
   "source": [
    "Install the Generative Models repo\n",
    "\n",
    "```\n",
    "!git clone https://github.com/Stability-AI/generative-models.git\n",
    "%cd generative-models\n",
    "\n",
    "!pip install -r requirements/pt2.txt -q\n",
    "!pip install . -q\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a502eaf-2547-408f-b623-06281248baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "from scripts.demo.streamlit_helpers import *\n",
    "from PIL import Image\n",
    "\n",
    "SD_XL_BASE_RATIOS = {\n",
    "    \"0.5\": (704, 1408),\n",
    "    \"0.52\": (704, 1344),\n",
    "    \"0.57\": (768, 1344),\n",
    "    \"0.6\": (768, 1280),\n",
    "    \"0.68\": (832, 1216),\n",
    "    \"0.72\": (832, 1152),\n",
    "    \"0.78\": (896, 1152),\n",
    "    \"0.82\": (896, 1088),\n",
    "    \"0.88\": (960, 1088),\n",
    "    \"0.94\": (960, 1024),\n",
    "    \"1.0\": (1024, 1024),\n",
    "    \"1.07\": (1024, 960),\n",
    "    \"1.13\": (1088, 960),\n",
    "    \"1.21\": (1088, 896),\n",
    "    \"1.29\": (1152, 896),\n",
    "    \"1.38\": (1152, 832),\n",
    "    \"1.46\": (1216, 832),\n",
    "    \"1.67\": (1280, 768),\n",
    "    \"1.75\": (1344, 768),\n",
    "    \"1.91\": (1344, 704),\n",
    "    \"2.0\": (1408, 704),\n",
    "    \"2.09\": (1472, 704),\n",
    "    \"2.4\": (1536, 640),\n",
    "    \"2.5\": (1600, 640),\n",
    "    \"2.89\": (1664, 576),\n",
    "    \"3.0\": (1728, 576),\n",
    "}\n",
    "\n",
    "VERSION2SPECS = {\n",
    "    \"SDXL-base-1.0\": {\n",
    "        \"H\": 1024,\n",
    "        \"W\": 1024,\n",
    "        \"C\": 4,\n",
    "        \"f\": 8,\n",
    "        \"is_legacy\": False,\n",
    "        \"config\": \"configs/inference/sd_xl_base.yaml\",\n",
    "        \"ckpt\": \"checkpoints/sd_xl_base_1.0.safetensors\",\n",
    "    },\n",
    "    \"SDXL-refiner-1.0\": {\n",
    "        \"H\": 1024,\n",
    "        \"W\": 1024,\n",
    "        \"C\": 4,\n",
    "        \"f\": 8,\n",
    "        \"is_legacy\": True,\n",
    "        \"config\": \"configs/inference/sd_xl_refiner.yaml\",\n",
    "        \"ckpt\": \"checkpoints/sd_xl_refiner_1.0.safetensors\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def load_img(display=True, key=None, device=\"cuda\"):\n",
    "    image = get_interactive_image(key=key)\n",
    "    if image is None:\n",
    "        return None\n",
    "    if display:\n",
    "        st.image(image)\n",
    "    w, h = image.size\n",
    "    print(f\"loaded input image of size ({w}, {h})\")\n",
    "    width, height = map(\n",
    "        lambda x: x - x % 64, (w, h)\n",
    "    )  # resize to integer multiple of 64\n",
    "    image = image.resize((width, height))\n",
    "    image = np.array(image.convert(\"RGB\"))\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image).to(dtype=torch.float32) / 127.5 - 1.0\n",
    "    return image.to(device)\n",
    "\n",
    "\n",
    "def run_txt2img(\n",
    "    state,\n",
    "    version,\n",
    "    version_dict,\n",
    "    is_legacy=False,\n",
    "    return_latents=False,\n",
    "    filter=None,\n",
    "    stage2strength=None,\n",
    "):\n",
    "    # SD_XL_BASE_RATIOS.values()\n",
    "    W, H = 1024, 1024\n",
    "    C = version_dict[\"C\"]\n",
    "    F = version_dict[\"f\"]\n",
    "\n",
    "    init_dict = {\n",
    "        \"orig_width\": W,\n",
    "        \"orig_height\": H,\n",
    "        \"target_width\": W,\n",
    "        \"target_height\": H,\n",
    "    }\n",
    "    value_dict = init_embedder_options(\n",
    "        get_unique_embedder_keys_from_conditioner(state[\"model\"].conditioner),\n",
    "        init_dict,\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "    )\n",
    "    sampler, num_rows, num_cols = init_sampling(stage2strength=stage2strength)\n",
    "    num_samples = num_rows * num_cols\n",
    "\n",
    "    out = do_sample(\n",
    "        state[\"model\"],\n",
    "        sampler,\n",
    "        value_dict,\n",
    "        num_samples,\n",
    "        H,\n",
    "        W,\n",
    "        C,\n",
    "        F,\n",
    "        force_uc_zero_embeddings=[\"txt\"] if not is_legacy else [],\n",
    "        return_latents=return_latents,\n",
    "        filter=filter,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_img2img(\n",
    "    state,\n",
    "    version_dict,\n",
    "    is_legacy=False,\n",
    "    return_latents=False,\n",
    "    filter=None,\n",
    "    stage2strength=None,\n",
    "):\n",
    "    img = load_img()\n",
    "    if img is None:\n",
    "        return None\n",
    "    H, W = img.shape[2], img.shape[3]\n",
    "\n",
    "    init_dict = {\n",
    "        \"orig_width\": W,\n",
    "        \"orig_height\": H,\n",
    "        \"target_width\": W,\n",
    "        \"target_height\": H,\n",
    "    }\n",
    "    value_dict = init_embedder_options(\n",
    "        get_unique_embedder_keys_from_conditioner(state[\"model\"].conditioner),\n",
    "        init_dict,\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "    )\n",
    "    strength = 0.75  # 0 to 1\n",
    "    sampler, num_rows, num_cols = init_sampling(\n",
    "        img2img_strength=strength,\n",
    "        stage2strength=stage2strength,\n",
    "    )\n",
    "    num_samples = num_rows * num_cols\n",
    "    out = do_img2img(\n",
    "        repeat(img, \"1 ... -> n ...\", n=num_samples),\n",
    "        state[\"model\"],\n",
    "        sampler,\n",
    "        value_dict,\n",
    "        num_samples,\n",
    "        force_uc_zero_embeddings=[\"txt\"] if not is_legacy else [],\n",
    "        return_latents=return_latents,\n",
    "        filter=filter,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def apply_refiner(\n",
    "    input,\n",
    "    state,\n",
    "    sampler,\n",
    "    num_samples,\n",
    "    prompt,\n",
    "    negative_prompt,\n",
    "    filter=None,\n",
    "    finish_denoising=False,\n",
    "):\n",
    "    init_dict = {\n",
    "        \"orig_width\": input.shape[3] * 8,\n",
    "        \"orig_height\": input.shape[2] * 8,\n",
    "        \"target_width\": input.shape[3] * 8,\n",
    "        \"target_height\": input.shape[2] * 8,\n",
    "    }\n",
    "\n",
    "    value_dict = init_dict\n",
    "    value_dict[\"prompt\"] = prompt\n",
    "    value_dict[\"negative_prompt\"] = negative_prompt\n",
    "\n",
    "    value_dict[\"crop_coords_top\"] = 0\n",
    "    value_dict[\"crop_coords_left\"] = 0\n",
    "\n",
    "    value_dict[\"aesthetic_score\"] = 6.0\n",
    "    value_dict[\"negative_aesthetic_score\"] = 2.5\n",
    "\n",
    "    st.warning(f\"refiner input shape: {input.shape}\")\n",
    "    samples = do_img2img(\n",
    "        input,\n",
    "        state[\"model\"],\n",
    "        sampler,\n",
    "        value_dict,\n",
    "        num_samples,\n",
    "        skip_encode=True,\n",
    "        filter=filter,\n",
    "        add_noise=not finish_denoising,\n",
    "    )\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lowvram_mode(True)\n",
    "seed_everything(1234)  # for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdad970-a3f0-44b8-8f69-905edf37a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"SDXL-base-1.0\"\n",
    "version_dict = VERSION2SPECS[version]\n",
    "mode = \"txt2img\"\n",
    "\n",
    "state = init_st(version_dict, load_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68996c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_legacy = False\n",
    "add_pipeline = False\n",
    "stage2strength=False\n",
    "negative_prompt=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cafb65-4372-4ee5-8563-99fd8ad1e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n",
    "prompt = \"Llama in a jungle, Lightning, AI themed, purple colors, detailed, 8k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4426594-07f1-4c78-9713-0da2b7d2eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run_txt2img(\n",
    "            state,\n",
    "            version,\n",
    "            version_dict,\n",
    "            is_legacy=is_legacy,\n",
    "            return_latents=add_pipeline,\n",
    "            filter=state.get(\"filter\"),\n",
    "            stage2strength=stage2strength,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863a0b4-190f-4447-886c-73afc78e0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "samples, samples_z = out, None\n",
    "if isinstance(out, (tuple, list)):\n",
    "    samples, samples_z = out\n",
    "    \n",
    "for sample in samples:\n",
    "    sample = 255.0 * rearrange(sample.cpu().numpy(), \"c h w -> h w c\")\n",
    "    image = Image.fromarray(sample.astype(np.uint8))\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08660a77-1ecd-4daa-9f46-9f917c5c49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].resize((512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6a95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
